{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef23dbb3",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc8e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/0C/ra93lal2/cma/CMA_Fairness_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/0C/ra93lal2/.local/share/virtualenvs/CMA_Fairness_v2-3j10GkSs/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/dss/dsshome1/0C/ra93lal2/.local/share/virtualenvs/CMA_Fairness_v2-3j10GkSs/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ~/cma/CMA_Fairness_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d235661",
   "metadata": {},
   "source": [
    "The following cell holds the definition of our parameters, these values can be overriden by rendering the with e.g. the following command:\n",
    "\n",
    "papermill -p alpha 0.2 -p ratio 0.3 universe_analysis.ipynb output/test_run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a789d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /dss/dsshome1/0C/ra93lal2/cma/CMA_Fairness_v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4132aaed",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "run_no = 0\n",
    "universe_id = \"test\"\n",
    "universe = {\n",
    "    \"training_size\": \"5k\", # \"25k\", \"5k\", \"1k\"\n",
    "    \"training_year\": \"2012_14\", # \"2014\", \"2012_14\", \"2010_14\"\n",
    "    \"scale\": \"scale\", # \"scale\", \"do-not-scale\",\n",
    "    \"model\": \"elasticnet\", # \"logreg\", \"penalized_logreg\", \"rf\", \"gbm\", \"elasticnet\"\n",
    "    \"cutoff\": [\"quantile_0.15\", \"quantile_0.30\"],\n",
    "    \"exclude_features\": \"age\", # \"none\", \"nationality\", \"sex\", \"nationality-sex\", \"age\"\n",
    "    \"exclude_subgroups\": \"drop-non-german\", # \"keep-all\", \"drop-non-german\"\n",
    "    \"eval_fairness_grouping\": [\"majority-minority\", \"nationality-all\"]\n",
    "}\n",
    "\n",
    "output_dir=\"./output\"\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d7941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if isinstance(universe, str):\n",
    "    universe = json.loads(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7076ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload the custom package\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport fairness_multiverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c8eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import UniverseAnalysis\n",
    "\n",
    "universe_analysis = UniverseAnalysis(\n",
    "    run_no = run_no,\n",
    "    universe_id = universe_id,\n",
    "    universe = universe,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6381cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "parsed_seed = int(seed)\n",
    "np.random.seed(parsed_seed)\n",
    "print(f\"Using Seed: {parsed_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e958b4",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98701482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SIAB data from cache: data/siab_cached.csv.gz\n",
      "(643690, 164)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "raw_file = Path(\"data/raw/siab.csv\")\n",
    "cache_file = Path(\"data/siab_cached.csv.gz\")\n",
    "\n",
    "# Ensure cache directory exists\n",
    "cache_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load with simple caching\n",
    "if cache_file.exists():\n",
    "    print(f\"Loading SIAB data from cache: {cache_file}\")\n",
    "    siab = pd.read_csv(cache_file, compression='gzip')\n",
    "else:\n",
    "    print(f\"Cache not found. Reading raw SIAB data: {raw_file}\")\n",
    "    siab = pd.read_csv(raw_file)\n",
    "    siab.to_csv(cache_file, index=False, compression='gzip')\n",
    "    print(f\"Cached SIAB data to: {cache_file}\")\n",
    "\n",
    "print(siab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058d2abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persnr</th>\n",
       "      <th>year</th>\n",
       "      <th>nrEntry</th>\n",
       "      <th>ltue</th>\n",
       "      <th>employed_before</th>\n",
       "      <th>receipt_leh_before</th>\n",
       "      <th>receipt_lhg_before</th>\n",
       "      <th>se_before</th>\n",
       "      <th>ASU_notue_seeking_before</th>\n",
       "      <th>ASU_other_before</th>\n",
       "      <th>...</th>\n",
       "      <th>minijob_tot_dur_byage</th>\n",
       "      <th>ft_tot_dur_byage</th>\n",
       "      <th>befrist_tot_dur_byage</th>\n",
       "      <th>leih_tot_dur_byage</th>\n",
       "      <th>LHG_tot_dur_byage</th>\n",
       "      <th>LEH_tot_dur_byage</th>\n",
       "      <th>almp_tot_dur_byage</th>\n",
       "      <th>almp_aw_tot_dur_byage</th>\n",
       "      <th>se_tot_dur_byage</th>\n",
       "      <th>seeking1_tot_dur_byage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.775510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.367347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643685</th>\n",
       "      <td>1827860</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643686</th>\n",
       "      <td>1827860</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>17.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643687</th>\n",
       "      <td>1827860</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>34.705882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.352941</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>23.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643688</th>\n",
       "      <td>1827869</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643689</th>\n",
       "      <td>1827869</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>8.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643690 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         persnr  year  nrEntry  ltue  employed_before  receipt_leh_before  \\\n",
       "0             7  2015        1     0                1                   0   \n",
       "1            18  2010        1     1                0                   0   \n",
       "2            18  2011        2     0                1                   0   \n",
       "3            18  2012        3     0                1                   0   \n",
       "4            18  2012        4     0                1                   0   \n",
       "...         ...   ...      ...   ...              ...                 ...   \n",
       "643685  1827860  2013        1     0                0                   0   \n",
       "643686  1827860  2015        2     1                0                   0   \n",
       "643687  1827860  2016        3     1                0                   0   \n",
       "643688  1827869  2013        1     1                1                   0   \n",
       "643689  1827869  2014        2     0                0                   1   \n",
       "\n",
       "        receipt_lhg_before  se_before  ASU_notue_seeking_before  \\\n",
       "0                        0          0                         1   \n",
       "1                        0          0                         0   \n",
       "2                        1          0                         1   \n",
       "3                        1          0                         1   \n",
       "4                        1          0                         1   \n",
       "...                    ...        ...                       ...   \n",
       "643685                   1          0                         0   \n",
       "643686                   1          0                         1   \n",
       "643687                   1          1                         0   \n",
       "643688                   0          0                         1   \n",
       "643689                   0          0                         1   \n",
       "\n",
       "        ASU_other_before  ...  minijob_tot_dur_byage  ft_tot_dur_byage  \\\n",
       "0                      0  ...               0.000000          0.000000   \n",
       "1                      0  ...               0.000000          0.000000   \n",
       "2                      0  ...               2.714286          2.714286   \n",
       "3                      0  ...               4.200000          4.200000   \n",
       "4                      0  ...               5.460000          5.460000   \n",
       "...                  ...  ...                    ...               ...   \n",
       "643685                 1  ...               0.000000          0.000000   \n",
       "643686                 0  ...               0.000000          0.000000   \n",
       "643687                 1  ...               0.000000          0.000000   \n",
       "643688                 0  ...               0.000000          0.000000   \n",
       "643689                 0  ...               0.000000          0.666667   \n",
       "\n",
       "        befrist_tot_dur_byage  leih_tot_dur_byage  LHG_tot_dur_byage  \\\n",
       "0                   15.043478            0.000000           0.000000   \n",
       "1                    0.000000            0.000000           0.000000   \n",
       "2                    0.000000            0.000000          10.775510   \n",
       "3                    0.000000            0.000000          12.100000   \n",
       "4                    0.000000            0.000000          13.360000   \n",
       "...                       ...                 ...                ...   \n",
       "643685               0.000000            0.000000           0.612903   \n",
       "643686               0.212121            0.212121          17.363636   \n",
       "643687               0.294118            0.205882          34.705882   \n",
       "643688               0.000000            0.000000           0.000000   \n",
       "643689               0.666667            0.000000           0.000000   \n",
       "\n",
       "        LEH_tot_dur_byage  almp_tot_dur_byage  almp_aw_tot_dur_byage  \\\n",
       "0                0.000000            0.000000               0.000000   \n",
       "1                0.000000            0.000000               0.000000   \n",
       "2                0.000000            8.367347               0.000000   \n",
       "3                0.000000            9.400000               0.000000   \n",
       "4                0.000000           10.320000               0.000000   \n",
       "...                   ...                 ...                    ...   \n",
       "643685           0.000000            0.000000               0.000000   \n",
       "643686           0.000000            8.909091               0.000000   \n",
       "643687           0.000000           10.352941               1.705882   \n",
       "643688           0.525424            0.000000               0.000000   \n",
       "643689           8.950000            1.033333               0.083333   \n",
       "\n",
       "        se_tot_dur_byage  seeking1_tot_dur_byage  \n",
       "0               0.000000                0.000000  \n",
       "1               0.000000                0.000000  \n",
       "2               0.000000                9.836735  \n",
       "3               0.000000                9.960000  \n",
       "4               0.000000               10.280000  \n",
       "...                  ...                     ...  \n",
       "643685          0.000000                0.000000  \n",
       "643686          0.000000                7.121212  \n",
       "643687          1.705882               23.911765  \n",
       "643688          0.000000                0.000000  \n",
       "643689          0.083333                8.133333  \n",
       "\n",
       "[643690 rows x 164 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87e805",
   "metadata": {},
   "source": [
    "# Splitting Data and Setting Training Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910ae358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import sample_by_year_size\n",
    "\n",
    "siab_train = sample_by_year_size(siab,\n",
    "                               training_year=universe[\"training_year\"],\n",
    "                               training_size=universe[\"training_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919c8ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siab_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feb13bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2012    1667\n",
       "2013    1667\n",
       "2014    1666\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(siab_train.groupby(\"year\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0997782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siab_train = siab_s[siab_s.year < 2015]\n",
    "siab_calib = siab[siab.year == 2015]\n",
    "siab_test = siab[siab.year == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1e4012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86692, 164)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#siab_calib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66b54ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89710, 164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#siab_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27e4384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = siab_train.iloc[:,4:164]\n",
    "y_train = siab_train.iloc[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ee8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_calib = siab_calib.iloc[:,4:164]\n",
    "y_calib = siab_calib.iloc[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ff42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = siab_test.iloc[:,4:164]\n",
    "y_true = siab_test.iloc[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0275101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary data needed downstream in the pipeline\n",
    "\n",
    "org_train = X_train.copy()\n",
    "org_test = X_test.copy()\n",
    "org_calib = X_calib.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461e618",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e74c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDE PROTECTED FEATURES\n",
    "# --------------------------\n",
    "\n",
    "excluded_features = universe[\"exclude_features\"].split(\"-\")\n",
    "excluded_features_dictionary = {\n",
    "    \"nationality\": [\"maxdeutsch1\", \"maxdeutsch.Missing.\"],\n",
    "    \"sex\": [\"frau1\"],\n",
    "    \"age\": [\"age\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e63555",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features_columns = [\n",
    "    excluded_features_dictionary[f] for f in excluded_features if len(f) > 0 and f != \"none\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da781f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import flatten_once\n",
    "\n",
    "excluded_features_columns = flatten_once(excluded_features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37fef0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features: ['age']\n"
     ]
    }
   ],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_train.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d029e3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features: ['age']\n"
     ]
    }
   ],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_test.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d571f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features: ['age']\n"
     ]
    }
   ],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_calib.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDE CERTAIN SUBGROUPS\n",
    "# -------------------------\n",
    "\n",
    "mode = universe.get(\"exclude_subgroups\", \"keep-all\") # Defaults to \"keep-all\" if the key is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"keep-all\":\n",
    "    keep_mask = pd.Series(True, index=org_train.index)\n",
    "\n",
    "elif mode == \"drop-non-german\":\n",
    "    keep_mask = (org_train[\"maxdeutsch1\"] == 1) & (org_train[\"maxdeutsch.Missing.\"] == 0)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported mode for exclude_subgroups: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b65474",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drop = (~keep_mask).sum() # Calculates how many rows are set to be dropped\n",
    "if n_drop > 0:\n",
    "    pct = n_drop / len(keep_mask) * 100\n",
    "    print(f\"Dropping {n_drop} rows ({pct:.2f}%) where mode='{mode}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[keep_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[keep_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d31e2f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db991733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "if (universe[\"model\"] == \"logreg\"):\n",
    "    model = LogisticRegression() #penalty=\"none\", solver=\"newton-cg\", max_iter=1)\n",
    "elif (universe[\"model\"] == \"penalized_logreg\"):\n",
    "    model = LogisticRegression(penalty=\"l2\", C=0.1) #, solver=\"newton-cg\", max_iter=1)\n",
    "elif (universe[\"model\"] == \"rf\"):\n",
    "    model = RandomForestClassifier() # n_estimators=100, n_jobs=-1\n",
    "elif (universe[\"model\"] == \"gbm\"):\n",
    "    model = GradientBoostingClassifier()\n",
    "elif (universe[\"model\"] == \"elasticnet\"):\n",
    "    model = LogisticRegression(penalty = 'elasticnet', solver = 'saga', l1_ratio = 0.5) # max_iter=5000\n",
    "else:\n",
    "    raise \"Unsupported universe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = Pipeline([\n",
    "    #(\"continuous_processor\", continuous_processor),\n",
    "    #(\"categorical_preprocessor\", categorical_preprocessor),\n",
    "    (\"scale\", StandardScaler() if universe[\"scale\"] == \"scale\" else None), \n",
    "    (\"model\", model),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import predict_w_threshold\n",
    "\n",
    "probs_test = model.predict_proba(X_test)\n",
    "\n",
    "'''\n",
    "Below code returns a boolean array (or binary 0/1 array depending on how it’s used) where each element \n",
    "is True if the probability of class 1 is greater than or equal to the threshold, and False otherwise.\n",
    "'''\n",
    "y_pred_default = predict_w_threshold(probs_test, 0.5)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Naive prediction\n",
    "accuracy_score(y_true = y_true, y_pred = y_pred_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759920c",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b27f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscoverage level for conformal prediction (10% allowed error rate => 90% target coverage)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59102472",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_calib = model.predict_proba(X_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_calib = y_calib.values.ravel().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650fd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import compute_nc_scores\n",
    "\n",
    "# Compute nonconformity scores on calibration set (1 - probability of true class)\n",
    "nc_scores = compute_nc_scores(probs_calib, y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ada44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import find_threshold\n",
    "\n",
    "# Find conformal threshold q_hat for the given alpha (split conformal method)\n",
    "q_hat = find_threshold(nc_scores, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import predict_conformal_sets\n",
    "\n",
    "# Generate prediction sets for each test example\n",
    "pred_sets = predict_conformal_sets(model, X_test, q_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f67a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import evaluate_sets\n",
    "\n",
    "# Evaluate coverage and average set size on test data\n",
    "metrics = evaluate_sets(pred_sets, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbacec0",
   "metadata": {},
   "source": [
    "# CP Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de55fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c340a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "universe_training_year = example_universe.get(\"training_year\")\n",
    "universe_training_size = example_universe.get(\"training_size\")\n",
    "universe_scale = example_universe.get(\"scale\")\n",
    "universe_model = example_universe.get(\"model\")\n",
    "universe_exclude_features = example_universe.get(\"exclude_features\")\n",
    "universe_exclude_subgroups = example_universe.get(\"exclude_subgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb53cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_dict = {\n",
    "    \"universe_id\": [universe_id],\n",
    "    \"universe_training_year\": [universe_training_year],\n",
    "    \"universe_training_size\": [universe_training_size],\n",
    "    \"universe_scale\": [universe_scale],\n",
    "    \"universe_model\": [universe_model],\n",
    "    \"universe_exclude_features\": [universe_exclude_features],\n",
    "    \"universe_exclude_subgroups\": [universe_exclude_subgroups],\n",
    "    \"q_hat\": [q_hat],\n",
    "    \"coverage\": [metrics[\"coverage\"]],\n",
    "    \"avg_size\": [metrics[\"avg_size\"]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_df = pd.DataFrame(cp_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed608b0b",
   "metadata": {},
   "source": [
    "Conditional coverage & looking at subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import build_cp_groups\n",
    "\n",
    "cp_groups_df = build_cp_groups(pred_sets, y_true, X_test.index, org_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ddabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covered = 1 if true_label is in the predicted set\n",
    "cp_groups_df['covered'] = cp_groups_df.apply(\n",
    "    lambda r: int(r['true_label'] in r['pred_set']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a261692",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = ['frau1','nongerman','nongerman_male','nongerman_female']\n",
    "\n",
    "# Conditional coverage for subgroup==1\n",
    "cond_coverage = {\n",
    "    g: cp_groups_df.loc[cp_groups_df[g]==1, 'covered'].mean()\n",
    "    for g in subgroups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942895c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subgroup, cov in cond_coverage.items():\n",
    "    cp_metrics_df[f\"cov_{subgroup}\"] = cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc519cc",
   "metadata": {},
   "source": [
    "# (Fairness) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname_to_bin = \"maxdeutsch1\"\n",
    "majority_value = org_train[colname_to_bin].mode()[0]\n",
    "\n",
    "org_test[\"majmin\"] = np.where(org_test[colname_to_bin] == majority_value, \"majority\", \"minority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "example_universe[\"cutoff\"] = example_universe[\"cutoff\"][0]\n",
    "example_universe[\"eval_fairness_grouping\"] = example_universe[\"eval_fairness_grouping\"][0]\n",
    "fairness_dict, metric_frame = universe_analysis.compute_metrics(\n",
    "    example_universe,\n",
    "    y_pred_prob=probs_test,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7a0e9",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1784b1",
   "metadata": {},
   "source": [
    "Main fairness target: Equalized Odds. Seems to be a better fit than equal opportunity, since we're not only interested in Y = 1. Seems to be a better fit than demographic parity, since we also care about accuracy, not just equal distribution of preds.\n",
    "\n",
    "Pick column for computation of fairness metrics\n",
    "\n",
    "Performance\n",
    "Overall performance measures, most interesting in relation to the measures split by group below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7672bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame.overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93333c9",
   "metadata": {},
   "source": [
    "By Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52256966",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a graphic\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e433ae",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_universes = universe_analysis.generate_sub_universes()\n",
    "len(sub_universes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sub_universe_data(sub_universe, org_test):\n",
    "    # Keep all rows — no filtering\n",
    "    keep_rows_mask = np.ones(org_test.shape[0], dtype=bool)\n",
    "\n",
    "    print(f\"[INFO] Keeping all rows: {keep_rows_mask.sum()} rows retained.\")\n",
    "    return keep_rows_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc31ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = universe_analysis.generate_final_output(\n",
    "    y_pred_prob=probs_test,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    "    filter_data=filter_sub_universe_data,\n",
    "    cp_metrics_df=cp_metrics_df,\n",
    "    save=True,\n",
    ")\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b80a1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c9fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (CMA Fairness)",
   "language": "python",
   "name": "cma_fair_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
