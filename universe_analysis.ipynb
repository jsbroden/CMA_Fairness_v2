{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f159f837-637b-42ba-96b5-ec9a68c44524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/0C/ra93lal2/cma/CMA_Fairness_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/0C/ra93lal2/.local/share/virtualenvs/CMA_Fairness_v2-3j10GkSs/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/dss/dsshome1/0C/ra93lal2/.local/share/virtualenvs/CMA_Fairness_v2-3j10GkSs/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ~/cma/CMA_Fairness_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2603b9",
   "metadata": {},
   "source": [
    "The following cell holds the definition of our parameters, these values can be overriden by rendering the with e.g. the following command:\n",
    "\n",
    "papermill -p alpha 0.2 -p ratio 0.3 universe_analysis.ipynb output/test_run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80968a0-40bb-4fa9-85ef-2d5eefb01975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /dss/dsshome1/0C/ra93lal2/cma/CMA_Fairness_v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dce4c03",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "run_no = 0\n",
    "universe_id = \"test\"\n",
    "universe = {\n",
    "    #\"scale\": \"scale\", # \"scale\", \"do-not-scale\",\n",
    "    #\"encode_categorical\": \"one-hot\", # \"ordinal\", \"one-hot\"\n",
    "    \"model\": \"elasticnet\", # \"logreg\", \"penalized_logreg\", \"rf\", \"gbm\", \"elasticnet\"\n",
    "    \"cutoff\": [\"quantile_0.15\", \"quantile_0.30\"],\n",
    "    \"exclude_features\": \"nationality-sex\", # \"none\", \"nationality\", \"sex\", \"nationality-sex\"\n",
    "    \"exclude_subgroups\": \"keep-all\", # \"keep-all\", \"drop-non-german\"\n",
    "    \"eval_fairness_grouping\": [\"majority-minority\", \"nationality-all\"]\n",
    "}\n",
    "\n",
    "output_dir=\"./output\"\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1650acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Parse universe into dict if it is passed as a string\n",
    "if isinstance(universe, str):\n",
    "    universe = json.loads(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16620c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload the custom package\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport fairness_multiverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c5c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import UniverseAnalysis\n",
    "\n",
    "universe_analysis = UniverseAnalysis(\n",
    "    run_no = run_no,\n",
    "    universe_id = universe_id,\n",
    "    universe = universe,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106241f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "parsed_seed = int(seed)\n",
    "np.random.seed(parsed_seed)\n",
    "print(f\"Using Seed: {parsed_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebdc57",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681925a3",
   "metadata": {},
   "source": [
    "Load siab_train, siab_test, siab_calib and/or \n",
    "load siab_train_features, siab_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0496b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SIAB data from cache: data/siab_cached.csv.gz\n",
      "(643690, 164)\n"
     ]
    }
   ],
   "source": [
    "# Do I need to load siab? Delete this cell?\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "raw_file = Path(\"data/raw/siab.csv\")\n",
    "cache_file = Path(\"data/siab_cached.csv.gz\")\n",
    "\n",
    "# Ensure cache directory exists\n",
    "cache_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load with simple caching\n",
    "if cache_file.exists():\n",
    "    print(f\"Loading SIAB data from cache: {cache_file}\")\n",
    "    siab = pd.read_csv(cache_file, compression='gzip')\n",
    "else:\n",
    "    print(f\"Cache not found. Reading raw SIAB data: {raw_file}\")\n",
    "    siab = pd.read_csv(raw_file)\n",
    "    siab.to_csv(cache_file, index=False, compression='gzip')\n",
    "    print(f\"Cached SIAB data to: {cache_file}\")\n",
    "\n",
    "# Now use `siab` DataFrame as needed\n",
    "print(siab.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0edb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"./data/X_train.csv\")\n",
    "y_train = pd.read_csv(\"./data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d08085",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"./data/X_test.csv\")\n",
    "y_true = pd.read_csv(\"./data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a8d0fa-1d3d-4ed8-bb2c-281470e24add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration data for conformal\n",
    "X_calib = pd.read_csv(\"./data/X_calib.csv\")\n",
    "y_calib = pd.read_csv(\"./data/y_calib.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6c733c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary data needed downstream in the pipeline\n",
    "\n",
    "#X_test, y_test \n",
    "\n",
    "org_train = X_train.copy()\n",
    "org_test = X_test.copy()\n",
    "org_calib = X_calib.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e33f5cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persnr</th>\n",
       "      <th>year</th>\n",
       "      <th>nrEntry</th>\n",
       "      <th>ltue</th>\n",
       "      <th>employed_before</th>\n",
       "      <th>receipt_leh_before</th>\n",
       "      <th>receipt_lhg_before</th>\n",
       "      <th>se_before</th>\n",
       "      <th>ASU_notue_seeking_before</th>\n",
       "      <th>ASU_other_before</th>\n",
       "      <th>...</th>\n",
       "      <th>minijob_tot_dur_byage</th>\n",
       "      <th>ft_tot_dur_byage</th>\n",
       "      <th>befrist_tot_dur_byage</th>\n",
       "      <th>leih_tot_dur_byage</th>\n",
       "      <th>LHG_tot_dur_byage</th>\n",
       "      <th>LEH_tot_dur_byage</th>\n",
       "      <th>almp_tot_dur_byage</th>\n",
       "      <th>almp_aw_tot_dur_byage</th>\n",
       "      <th>se_tot_dur_byage</th>\n",
       "      <th>seeking1_tot_dur_byage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.775510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.367347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643685</th>\n",
       "      <td>1827860</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643686</th>\n",
       "      <td>1827860</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>17.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643687</th>\n",
       "      <td>1827860</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>34.705882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.352941</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>23.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643688</th>\n",
       "      <td>1827869</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643689</th>\n",
       "      <td>1827869</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>8.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643690 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         persnr  year  nrEntry  ltue  employed_before  receipt_leh_before  \\\n",
       "0             7  2015        1     0                1                   0   \n",
       "1            18  2010        1     1                0                   0   \n",
       "2            18  2011        2     0                1                   0   \n",
       "3            18  2012        3     0                1                   0   \n",
       "4            18  2012        4     0                1                   0   \n",
       "...         ...   ...      ...   ...              ...                 ...   \n",
       "643685  1827860  2013        1     0                0                   0   \n",
       "643686  1827860  2015        2     1                0                   0   \n",
       "643687  1827860  2016        3     1                0                   0   \n",
       "643688  1827869  2013        1     1                1                   0   \n",
       "643689  1827869  2014        2     0                0                   1   \n",
       "\n",
       "        receipt_lhg_before  se_before  ASU_notue_seeking_before  \\\n",
       "0                        0          0                         1   \n",
       "1                        0          0                         0   \n",
       "2                        1          0                         1   \n",
       "3                        1          0                         1   \n",
       "4                        1          0                         1   \n",
       "...                    ...        ...                       ...   \n",
       "643685                   1          0                         0   \n",
       "643686                   1          0                         1   \n",
       "643687                   1          1                         0   \n",
       "643688                   0          0                         1   \n",
       "643689                   0          0                         1   \n",
       "\n",
       "        ASU_other_before  ...  minijob_tot_dur_byage  ft_tot_dur_byage  \\\n",
       "0                      0  ...               0.000000          0.000000   \n",
       "1                      0  ...               0.000000          0.000000   \n",
       "2                      0  ...               2.714286          2.714286   \n",
       "3                      0  ...               4.200000          4.200000   \n",
       "4                      0  ...               5.460000          5.460000   \n",
       "...                  ...  ...                    ...               ...   \n",
       "643685                 1  ...               0.000000          0.000000   \n",
       "643686                 0  ...               0.000000          0.000000   \n",
       "643687                 1  ...               0.000000          0.000000   \n",
       "643688                 0  ...               0.000000          0.000000   \n",
       "643689                 0  ...               0.000000          0.666667   \n",
       "\n",
       "        befrist_tot_dur_byage  leih_tot_dur_byage  LHG_tot_dur_byage  \\\n",
       "0                   15.043478            0.000000           0.000000   \n",
       "1                    0.000000            0.000000           0.000000   \n",
       "2                    0.000000            0.000000          10.775510   \n",
       "3                    0.000000            0.000000          12.100000   \n",
       "4                    0.000000            0.000000          13.360000   \n",
       "...                       ...                 ...                ...   \n",
       "643685               0.000000            0.000000           0.612903   \n",
       "643686               0.212121            0.212121          17.363636   \n",
       "643687               0.294118            0.205882          34.705882   \n",
       "643688               0.000000            0.000000           0.000000   \n",
       "643689               0.666667            0.000000           0.000000   \n",
       "\n",
       "        LEH_tot_dur_byage  almp_tot_dur_byage  almp_aw_tot_dur_byage  \\\n",
       "0                0.000000            0.000000               0.000000   \n",
       "1                0.000000            0.000000               0.000000   \n",
       "2                0.000000            8.367347               0.000000   \n",
       "3                0.000000            9.400000               0.000000   \n",
       "4                0.000000           10.320000               0.000000   \n",
       "...                   ...                 ...                    ...   \n",
       "643685           0.000000            0.000000               0.000000   \n",
       "643686           0.000000            8.909091               0.000000   \n",
       "643687           0.000000           10.352941               1.705882   \n",
       "643688           0.525424            0.000000               0.000000   \n",
       "643689           8.950000            1.033333               0.083333   \n",
       "\n",
       "        se_tot_dur_byage  seeking1_tot_dur_byage  \n",
       "0               0.000000                0.000000  \n",
       "1               0.000000                0.000000  \n",
       "2               0.000000                9.836735  \n",
       "3               0.000000                9.960000  \n",
       "4               0.000000               10.280000  \n",
       "...                  ...                     ...  \n",
       "643685          0.000000                0.000000  \n",
       "643686          0.000000                7.121212  \n",
       "643687          1.705882               23.911765  \n",
       "643688          0.000000                0.000000  \n",
       "643689          0.083333                8.133333  \n",
       "\n",
       "[643690 rows x 164 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49c3ce",
   "metadata": {},
   "source": [
    "Pre-Processing for Selected Task -> skipped. I think I don't need this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a1b33",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca879031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDE PROTECTED FEATURES\n",
    "# ----------------------\n",
    "# \"exclude_features\": \"none\", # \"nationality\", \"sex\", \"nationality-sex\"\n",
    "\n",
    "excluded_features = universe[\"exclude_features\"].split(\"-\") # split, e.g.: \"nationality-sex\" -> [\"nationality\", \"sex\"]\n",
    "excluded_features_dictionary = {\n",
    "    \"nationality\": [\"maxdeutsch1\", \"maxdeutsch.Missing.\"],\n",
    "    \"sex\": [\"frau1\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b745ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code nice names to column names\n",
    "\n",
    "excluded_features_columns = [\n",
    "    excluded_features_dictionary[f] for f in excluded_features if len(f) > 0 and f != \"none\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f84f73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import flatten_once\n",
    "\n",
    "excluded_features_columns = flatten_once(excluded_features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884dea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features: ['maxdeutsch1', 'maxdeutsch.Missing.', 'frau1']\n"
     ]
    }
   ],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_train.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95ab8b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features: ['maxdeutsch1', 'maxdeutsch.Missing.', 'frau1']\n"
     ]
    }
   ],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_test.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76c4dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDE CERTAIN SUBGROUPS\n",
    "# ----------------------\n",
    "\n",
    "mode = universe.get(\"exclude_subgroups\", \"keep-all\") \n",
    "# Fetches the exclude_subgroups setting from the universe dict.\n",
    "# Defaults to \"keep-all\" if the key is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21994072",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"keep-all\":\n",
    "    keep_mask = pd.Series(True, index=org_train.index)\n",
    "\n",
    "# org_train contains the original feature columns from features_org (in Simson)\n",
    "# features_org contains unprocessed features, for me X_train at beginning ???\n",
    "# For keep-all, creates a boolean Series (keep_mask) of all True, so no rows are removed.\n",
    "\n",
    "elif mode == \"drop-non-german\":\n",
    "    keep_mask = org_train[\"maxdeutsch1\"] == 1 # ??? what about missing values?\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported mode for exclude_subgroups: {mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71651440",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drop = (~keep_mask).sum() # Calculates how many rows are set to be dropped\n",
    "if n_drop > 0:\n",
    "    pct = n_drop / len(keep_mask) * 100\n",
    "    print(f\"Dropping {n_drop} rows ({pct:.2f}%) where mode='{mode}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb8eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[keep_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b202bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[keep_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e2ac3",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "679e1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "if (universe[\"model\"] == \"logreg\"):\n",
    "    model = LogisticRegression() #penalty=\"none\") #, solver=\"newton-cg\", max_iter=1) # include random_state=19 ?\n",
    "elif (universe[\"model\"] == \"penalized_logreg\"):\n",
    "    model = LogisticRegression(penalty=\"l2\", C=1.0) #, solver=\"newton-cg\", max_iter=1)\n",
    "elif (universe[\"model\"] == \"rf\"):\n",
    "    model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "elif (universe[\"model\"] == \"gbm\"):\n",
    "    model = GradientBoostingClassifier()\n",
    "elif (universe[\"model\"] == \"elasticnet\"):\n",
    "    model = LogisticRegression(penalty = 'elasticnet', solver = 'saga', l1_ratio = 0.5) # which solver to use?\n",
    "else:\n",
    "    raise \"Unsupported universe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af59f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import predict_w_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cc8f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = Pipeline([\n",
    "    #(\"continuous_processor\", continuous_processor),\n",
    "    #(\"categorical_preprocessor\", categorical_preprocessor),\n",
    "    #(\"scale\", StandardScaler() if universe[\"scale\"] == \"scale\" else None),\n",
    "    (\"model\", model),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9442c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/0C/ra93lal2/.local/share/virtualenvs/CMA_Fairness_v2-3j10GkSs/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 LogisticRegression(l1_ratio=0.5, penalty=&#x27;elasticnet&#x27;,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 LogisticRegression(l1_ratio=0.5, penalty=&#x27;elasticnet&#x27;,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(l1_ratio=0.5, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 LogisticRegression(l1_ratio=0.5, penalty='elasticnet',\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "'''\n",
    "Below code returns a boolean array (or binary 0/1 array depending on how it’s used) where each element \n",
    "is True if the probability of class 1 is greater than or equal to the threshold, and False otherwise.\n",
    "'''\n",
    "y_pred_default = predict_w_threshold(y_prob, 0.5)\n",
    "\n",
    "# Naive prediction\n",
    "accuracy_score(y_true = y_true, y_pred = y_pred_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081964c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9705b",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ec6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33774451",
   "metadata": {},
   "source": [
    "# (Fairness) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do I need to include maxdeutsch1.missing?\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "colname_to_bin = \"maxdeutsch1\"\n",
    "majority_value = org_train[colname_to_bin].mode()[0]\n",
    "\n",
    "org_test[\"majmin\"] = np.where(org_test[colname_to_bin] == majority_value, \"majority\", \"minority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a50de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "example_universe[\"cutoff\"] = example_universe[\"cutoff\"][0]\n",
    "example_universe[\"eval_fairness_grouping\"] = example_universe[\"eval_fairness_grouping\"][0]\n",
    "fairness_dict, metric_frame = universe_analysis.compute_metrics(\n",
    "    example_universe,\n",
    "    y_pred_prob=y_prob,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d4e02",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee4871",
   "metadata": {},
   "source": [
    "Fairness\n",
    "Main fairness target: Equalized Odds. Seems to be a better fit than equal opportunity, since we're not only interested in Y = 1. Seems to be a better fit than demographic parity, since we also care about accuracy, not just equal distribution of preds.\n",
    "\n",
    "Pick column for computation of fairness metrics\n",
    "\n",
    "Performance\n",
    "Overall performance measures, most interesting in relation to the measures split by group below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e067c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame.overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e968fe9d",
   "metadata": {},
   "source": [
    "By Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec325bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ddbe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a graphic\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a0bac",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d280a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_universes = universe_analysis.generate_sub_universes()\n",
    "len(sub_universes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92adf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sub_universe_data(sub_universe, org_test):\n",
    "    # Keep all rows — no filtering\n",
    "    keep_rows_mask = np.ones(org_test.shape[0], dtype=bool)\n",
    "\n",
    "    print(f\"[INFO] Keeping all rows: {keep_rows_mask.sum()} rows retained.\")\n",
    "    return keep_rows_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a759155",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = universe_analysis.generate_final_output(\n",
    "    y_pred_prob=y_prob,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    "    save=True,\n",
    "    filter_data=filter_sub_universe_data\n",
    ")\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ff514-cb11-46f8-b6fc-50392f74b5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (CMA Fairness)",
   "language": "python",
   "name": "cma_fair_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
