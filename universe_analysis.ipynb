{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4a28de",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e04305",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/cma/CMA_Fairness_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07fec0",
   "metadata": {},
   "source": [
    "The following cell holds the definition of our parameters, these values can be overriden by rendering the with e.g. the following command:\n",
    "\n",
    "papermill -p alpha 0.2 -p ratio 0.3 universe_analysis.ipynb output/test_run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa5173",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "run_no = 0\n",
    "universe_id = \"test\"\n",
    "universe = {\n",
    "    \"training_size\": \"5k\", # \"25k\", \"5k\", \"1k\"\n",
    "    \"training_year\": \"2012_14\", # \"2014\", \"2012_14\", \"2010_14\"\n",
    "    \"scale\": \"scale\", # \"scale\", \"do-not-scale\",\n",
    "    \"model\": \"elasticnet\", # \"logreg\", \"penalized_logreg\", \"rf\", \"gbm\", \"elasticnet\"\n",
    "    \"cutoff\": [\"quantile_0.15\", \"quantile_0.30\"],\n",
    "    \"exclude_features\": \"age\", # \"none\", \"nationality\", \"sex\", \"nationality-sex\", \"age\"\n",
    "    \"exclude_subgroups\": \"drop-non-german\", # \"keep-all\", \"drop-non-german\"\n",
    "    \"eval_fairness_grouping\": [\"majority-minority\", \"nationality-all\"]\n",
    "}\n",
    "\n",
    "output_dir=\"./output\"\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfe5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if isinstance(universe, str):\n",
    "    universe = json.loads(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload the custom package\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport fairness_multiverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d487dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import UniverseAnalysis\n",
    "\n",
    "universe_analysis = UniverseAnalysis(\n",
    "    run_no = run_no,\n",
    "    universe_id = universe_id,\n",
    "    universe = universe,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7834a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parsed_seed = int(seed)\n",
    "np.random.seed(parsed_seed)\n",
    "print(f\"Using Seed: {parsed_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43177fd1",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "raw_file = Path(\"data/raw/siab.csv\")\n",
    "cache_file = Path(\"data/siab_cached.csv.gz\")\n",
    "\n",
    "# Ensure cache directory exists\n",
    "cache_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load with simple caching\n",
    "if cache_file.exists():\n",
    "    print(f\"Loading SIAB data from cache: {cache_file}\")\n",
    "    siab = pd.read_csv(cache_file, compression='gzip')\n",
    "else:\n",
    "    print(f\"Cache not found. Reading raw SIAB data: {raw_file}\")\n",
    "    siab = pd.read_csv(raw_file)\n",
    "    siab.to_csv(cache_file, index=False, compression='gzip')\n",
    "    print(f\"Cached SIAB data to: {cache_file}\")\n",
    "\n",
    "print(siab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0975982",
   "metadata": {},
   "outputs": [],
   "source": [
    "siab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593a58d",
   "metadata": {},
   "source": [
    "# Splitting Data and Setting Training Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import sample_by_year_size\n",
    "\n",
    "siab_train = sample_by_year_size(siab,\n",
    "                               training_year=universe[\"training_year\"],\n",
    "                               training_size=universe[\"training_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "siab_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(siab_train.groupby(\"year\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siab_train = siab_s[siab_s.year < 2015]\n",
    "siab_calib = siab[siab.year == 2015]\n",
    "siab_test = siab[siab.year == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siab_calib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb92963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siab_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = siab_train.iloc[:,4:164]\n",
    "y_train = siab_train.iloc[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_calib = siab_calib.iloc[:,4:164]\n",
    "y_calib = siab_calib.iloc[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = siab_test.iloc[:,4:164]\n",
    "y_true = siab_test.iloc[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbd296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary data needed downstream in the pipeline\n",
    "\n",
    "org_train = X_train.copy()\n",
    "org_test = X_test.copy()\n",
    "org_calib = X_calib.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed573d",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14553d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDE PROTECTED FEATURES\n",
    "# --------------------------\n",
    "\n",
    "excluded_features = universe[\"exclude_features\"].split(\"-\")\n",
    "excluded_features_dictionary = {\n",
    "    \"nationality\": [\"maxdeutsch1\", \"maxdeutsch.Missing.\"],\n",
    "    \"sex\": [\"frau1\"],\n",
    "    \"age\": [\"age\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features_columns = [\n",
    "    excluded_features_dictionary[f] for f in excluded_features if len(f) > 0 and f != \"none\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39140e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import flatten_once\n",
    "\n",
    "excluded_features_columns = flatten_once(excluded_features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7140606",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_train.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_test.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(excluded_features_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_features_columns}\")\n",
    "    X_calib.drop(excluded_features_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDE CERTAIN SUBGROUPS\n",
    "# -------------------------\n",
    "\n",
    "mode = universe.get(\"exclude_subgroups\", \"keep-all\") # Defaults to \"keep-all\" if the key is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"keep-all\":\n",
    "    keep_mask = pd.Series(True, index=org_train.index)\n",
    "\n",
    "elif mode == \"drop-non-german\":\n",
    "    keep_mask = (org_train[\"maxdeutsch1\"] == 1) & (org_train[\"maxdeutsch.Missing.\"] == 0)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported mode for exclude_subgroups: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drop = (~keep_mask).sum() # Calculates how many rows are set to be dropped\n",
    "if n_drop > 0:\n",
    "    pct = n_drop / len(keep_mask) * 100\n",
    "    print(f\"Dropping {n_drop} rows ({pct:.2f}%) where mode='{mode}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed875e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[keep_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[keep_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311393b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f35238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "if (universe[\"model\"] == \"logreg\"):\n",
    "    model = LogisticRegression() #penalty=\"none\", solver=\"newton-cg\", max_iter=1)\n",
    "elif (universe[\"model\"] == \"penalized_logreg\"):\n",
    "    model = LogisticRegression(penalty=\"l2\", C=0.1) #, solver=\"newton-cg\", max_iter=1)\n",
    "elif (universe[\"model\"] == \"rf\"):\n",
    "    model = RandomForestClassifier() # n_estimators=100, n_jobs=-1\n",
    "elif (universe[\"model\"] == \"gbm\"):\n",
    "    model = GradientBoostingClassifier()\n",
    "elif (universe[\"model\"] == \"elasticnet\"):\n",
    "    model = LogisticRegression(penalty = 'elasticnet', solver = 'saga', l1_ratio = 0.5) # max_iter=5000\n",
    "else:\n",
    "    raise \"Unsupported universe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da03102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = Pipeline([\n",
    "    #(\"continuous_processor\", continuous_processor),\n",
    "    #(\"categorical_preprocessor\", categorical_preprocessor),\n",
    "    (\"scale\", StandardScaler() if universe[\"scale\"] == \"scale\" else None), \n",
    "    (\"model\", model),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea094725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ee67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import predict_w_threshold\n",
    "\n",
    "probs_test = model.predict_proba(X_test)\n",
    "\n",
    "'''\n",
    "Below code returns a boolean array (or binary 0/1 array depending on how it’s used) where each element \n",
    "is True if the probability of class 1 is greater than or equal to the threshold, and False otherwise.\n",
    "'''\n",
    "y_pred_default = predict_w_threshold(probs_test, 0.5)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Naive prediction\n",
    "accuracy_score(y_true = y_true, y_pred = y_pred_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deec600",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40330c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscoverage level for conformal prediction (10% allowed error rate => 90% target coverage)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68cd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_calib = model.predict_proba(X_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7510317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_calib = y_calib.values.ravel().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6eeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import compute_nc_scores\n",
    "\n",
    "# Compute nonconformity scores on calibration set (1 - probability of true class)\n",
    "nc_scores = compute_nc_scores(probs_calib, y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31673cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import find_threshold\n",
    "\n",
    "# Find conformal threshold q_hat for the given alpha (split conformal method)\n",
    "q_hat = find_threshold(nc_scores, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56852c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e28d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import predict_conformal_sets\n",
    "\n",
    "# Generate prediction sets for each test example\n",
    "pred_sets = predict_conformal_sets(model, X_test, q_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f916c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import evaluate_sets\n",
    "\n",
    "# Evaluate coverage and average set size on test data\n",
    "metrics = evaluate_sets(pred_sets, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece5441",
   "metadata": {},
   "source": [
    "# CP Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca859d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "universe_training_year = example_universe.get(\"training_year\")\n",
    "universe_training_size = example_universe.get(\"training_size\")\n",
    "universe_scale = example_universe.get(\"scale\")\n",
    "universe_model = example_universe.get(\"model\")\n",
    "universe_exclude_features = example_universe.get(\"exclude_features\")\n",
    "universe_exclude_subgroups = example_universe.get(\"exclude_subgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_dict = {\n",
    "    \"universe_id\": [universe_id],\n",
    "    \"universe_training_year\": [universe_training_year],\n",
    "    \"universe_training_size\": [universe_training_size],\n",
    "    \"universe_scale\": [universe_scale],\n",
    "    \"universe_model\": [universe_model],\n",
    "    \"universe_exclude_features\": [universe_exclude_features],\n",
    "    \"universe_exclude_subgroups\": [universe_exclude_subgroups],\n",
    "    \"q_hat\": [q_hat],\n",
    "    \"coverage\": [metrics[\"coverage\"]],\n",
    "    \"avg_size\": [metrics[\"avg_size\"]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_df = pd.DataFrame(cp_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249125b",
   "metadata": {},
   "source": [
    "Conditional coverage & looking at subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddda9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_multiverse.conformal import build_cp_groups\n",
    "\n",
    "cp_groups_df = build_cp_groups(pred_sets, y_true, X_test.index, org_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covered = 1 if true_label is in the predicted set\n",
    "cp_groups_df['covered'] = cp_groups_df.apply(\n",
    "    lambda r: int(r['true_label'] in r['pred_set']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a424ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = ['frau1','nongerman','nongerman_male','nongerman_female']\n",
    "\n",
    "# Conditional coverage for subgroup==1\n",
    "cond_coverage = {\n",
    "    g: cp_groups_df.loc[cp_groups_df[g]==1, 'covered'].mean()\n",
    "    for g in subgroups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2178ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subgroup, cov in cond_coverage.items():\n",
    "    cp_metrics_df[f\"cov_{subgroup}\"] = cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0579e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415b59e",
   "metadata": {},
   "source": [
    "# (Fairness) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname_to_bin = \"maxdeutsch1\"\n",
    "majority_value = org_train[colname_to_bin].mode()[0]\n",
    "\n",
    "org_test[\"majmin\"] = np.where(org_test[colname_to_bin] == majority_value, \"majority\", \"minority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "example_universe[\"cutoff\"] = example_universe[\"cutoff\"][0]\n",
    "example_universe[\"eval_fairness_grouping\"] = example_universe[\"eval_fairness_grouping\"][0]\n",
    "fairness_dict, metric_frame = universe_analysis.compute_metrics(\n",
    "    example_universe,\n",
    "    y_pred_prob=probs_test,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65e85d",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15561f4",
   "metadata": {},
   "source": [
    "Main fairness target: Equalized Odds. Seems to be a better fit than equal opportunity, since we're not only interested in Y = 1. Seems to be a better fit than demographic parity, since we also care about accuracy, not just equal distribution of preds.\n",
    "\n",
    "Pick column for computation of fairness metrics\n",
    "\n",
    "Performance\n",
    "Overall performance measures, most interesting in relation to the measures split by group below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame.overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b3a27",
   "metadata": {},
   "source": [
    "By Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1120ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a graphic\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adec0ca",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_universes = universe_analysis.generate_sub_universes()\n",
    "len(sub_universes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39198174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sub_universe_data(sub_universe, org_test):\n",
    "    # Keep all rows — no filtering\n",
    "    keep_rows_mask = np.ones(org_test.shape[0], dtype=bool)\n",
    "\n",
    "    print(f\"[INFO] Keeping all rows: {keep_rows_mask.sum()} rows retained.\")\n",
    "    return keep_rows_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0354fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = universe_analysis.generate_final_output(\n",
    "    y_pred_prob=probs_test,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    "    filter_data=filter_sub_universe_data,\n",
    "    cp_metrics_df=cp_metrics_df,\n",
    "    save=True,\n",
    ")\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919cbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (CMA Fairness)",
   "language": "python",
   "name": "cma_fair_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
