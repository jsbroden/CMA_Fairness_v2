{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When working in AI LRZ\n",
    "%cd ~/cma/CMA_Fairness_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload the custom package\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport fairness_multiverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TO_ANALYSE = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"output\") / \"runs\" / str(RUN_TO_ANALYSE) / \"cp_metrics\"\n",
    "CP_DIR = Path(\"output\") / \"runs\" / str(RUN_TO_ANALYSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cp_metric = \"avg_size\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files into a list of dataframes\n",
    "csv_files = list(DATA_DIR.glob(\"*.csv\"))\n",
    "frames = [pd.read_csv(file) for file in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them into one DataFrame\n",
    "df = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(CP_DIR / \"combined_cp_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#\n",
    "#df_settings = pd.json_normalize(\n",
    "#    df_agg_raw[\"universe_settings\"].apply(json.loads)\n",
    "#).add_prefix(\n",
    "#    PREFIX_SETTINGS\n",
    "#)\n",
    "#\n",
    "#df_agg_full = df_settings.join(df_agg_raw)\n",
    "#df_agg_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = df.shape\n",
    "print(f\"The data has N = {rows} rows and N = {columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_settings = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_SETTINGS)])\n",
    "#cols_eval = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_EVAL)])\n",
    "#cols_non_eval = list(set(cols_settings) - set(cols_eval))\n",
    "#cols_performance = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_PERFORMANCE)])\n",
    "#cols_fairness = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_FAIRNESS)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"universe_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_mask = df_agg_full[\"sett_exclude_subgroups\"].isin(['drop-non-german'])\n",
    "#print(f\"Dropping N = {drop_mask.sum()} rows, keeping N = {(~drop_mask).sum()}\")\n",
    "#\n",
    "#df_agg_full = df_agg_full[~drop_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_agg_full[\"sett_exclude_subgroups\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_agg_full[\"sett_eval_fairness_grouping\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_agg_full[\"sett_eval_exclude_subgroups\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_agg_full[\"sett_eval_on_subset\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CMA Fairness)",
   "language": "python",
   "name": "cma_fair_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
